Digitizer/Digitizer.tex:Les principaux modèles pour décrire les interactions hadroniques de haute énergie avec la matière sont les modèles de cordes partoniques (cf. section~\ref{sec.parton}). Ces modèles sont valables pour des énergies supérieures à $5-10$ GeV. Les interactions aux énergies intermédiaires (100 MeV < E < 10 GeV) sont décrites avec les modèles de cascades intranucléaires (cf. section~\ref{sec.inucl}). Pour traiter les noyaux excités par des collisions de plus haute énergie et les interactions en dessous de 200 MeV, une famille de modèles de désexcitation nucléaire (fission, évaporation nucléaire\dots) est disponible. Les interactions des neutrons de basse énergie (E<20 MeV) peuvent être simulées avec des modèles de haute précision pour neutrons où un grand nombre de sections efficaces ont été tabulées. L'utilisation ou non de ces modèles de haute précision pour les neutrons aura des conséquences sur le temps de calcul, sur la réponse simulée du détecteur ou sur la topologie des gerbes.
Digitizer/Digitizer.tex:Le modèle de Bertini a été étendu, il est valable pour des particules incidentes ($p$, $n$, $\pi$, $K$, $\Delta$, $\Sigma$, $\Xi$, $\Omega$ et $\gamma$) avec une énergie cinétique comprise entre 100 MeV et 10 GeV~\cite{geant4_bertini}. Ce modèle est applicable lorsque la longueur d'onde de de Broglie de la particule incidente est du même ordre que la distance moyenne entre les nucléons du noyau et lorsque l'énergie de la particule incidente est supérieure à l'énergie de Fermi. Le noyau cible est modélisé par une ou trois couches concentriques de densité constante en fonction du nombre de nucléons dans le noyau (1 couche si A<4, 3 sinon). La cascade commence lorsqu'une particule incidente rencontre un nucléon du noyau cible. Le point d'impact de la particule incidente est choisi aléatoirement dans une distribution sphérique uniforme. Les sections efficaces entre la particule et les nucléons, la densité de nucléons et les impulsions des nucléons sont utilisées pour calculer le libre parcours de la particule. Les impulsions des nucléons sont calculées en utilisant le modèle du gaz de Fermi. Une collision entre la particule incidente et un nucléon peut produire des particules secondaires. Pour les pions, le modèle de Bertini prend en charge les collisions élastiques et les collisions inélastiques suivantes: $\pi^-p\rightarrow\pi^0n$, $\pi^0p\rightarrow\pi^+n$, $\pi^0n\rightarrow\pi^-p$, et $\pi^+n\rightarrow\pi^0p$. Des réactions produisant plus de 2 particules sont aussi implémentées. Les pions peuvent aussi être absorbés par les nucléons par le biais des réactions de la forme: $\pi^-pp\rightarrow np$. Les impulsions du nucléon et des particules secondaires créées sont calculées. Ces particules secondaires sont alors susceptibles d'interagir à leur tour avec les nucléons du noyau si leur énergie cinétique est supérieure à 2 $MeV$. La valeur de cette coupure vient du principe d'exclusion de Pauli. Les produits d'une réaction initiée par une particule d'énergie inférieure à une valeur approximative de 2 $MeV$ auraient une énergie encore plus faible. Or dans un gaz de Fermi, les niveaux d'énergie les plus bas sont remplis, empêchant d’accueillir de nouveaux nucléons avec une énergie inférieure à celle de Fermi. L'énergie minimale pour la production de nouvelles particules correspond au plus faible niveau d'énergie non rempli. Pour simplifier le modèle et tenir compte du principe de Pauli, l'énergie de Fermi est choisie à 2 $MeV$. La cascade intranucléaire prend fin lorsque toutes les particules secondaires sont absorbées ou se sont échappées du noyau. Le noyau est alors dans un état excité: des nucléons du noyau ont changé de niveau d'énergie. Un modèle de désexcitation est alors utilisé pour traiter les transitions de ces nucléons. Les noyaux résultants peuvent être instables et seront traités avec des modèles de fission et d'évaporation nucléaire.
Digitizer/Digitizer.tex:\item La fenêtre en temps utilisée dans la procédure de reconstruction des événements décrite dans la partie~\ref{sec.trivent} du chapitre~\ref{chap.sdhcal} est de 1000 $ns$ (5 coups d'horloge de 200 $ns$ pour reconstruire un événement physique). Ainsi, les particules interagissant tardivement dans le détecteur comme les neutrons peuvent ne pas être associées à l’événement. Pour prendre cet effet en compte, les segments dont le temps d’occurrence est supérieur à 1000 $ns$ sont supprimés.
Digitizer/Digitizer.tex:\item Les seuils sont finalement appliqués pour toutes les cellules. Les cellules pour lesquelles la charge induite est supérieure à la valeur du premier seuil sont étiquetés selon la valeur de cette charge. Les autres cellules ne créent pas de hits. 
Digitizer/Digitizer.tex:Nous avons vu dans la section~\ref{sec.sdhcal_thr} du chapitre~\ref{chap.sdhcal} comment les seuils sont réglés dans le prototype. Cependant comme ces travaux n'ont pas pu être effectués avec des détecteurs complets, il est probable que les valeurs de conversion (entre DAC et valeurs de seuil en $pC$) soient légèrement différentes pour le prototype. Ceci donne un peu de liberté pour régler les seuils dans la simulation. Les études de scan en seuil (cf. figures~\ref{fig.thrScan}(b)) montre qu'une faible variation du premier seuil ($seuil\in[0.1,0.4]~pC$) a des conséquences négligeables sur l'efficacité ($\varepsilon\in[0.94,0.95]$). Ainsi, la valeur du premier seuil utilisée dans la simulation est fixé à 0.114 $pC$ comme pour le prototype. Pour régler la valeur des seuils supérieurs, nous avons de nouveau réalisé une étude d'efficacité. La même méthode décrite dans le chapitre~\ref{chap.sdhcal} est utilisée pour déterminer si un plan est efficace. Lorsqu'un plan est efficace, il est aussi considéré comme efficace pour les seuils 2 et/ou 3 si au moins une cellule ayant une charge qui a passé ces seuils ces seuils, est trouvé dans l'amas de cellules associées. Les seuils 2 et 3 sont alors réglés pour reproduire les efficacités des données expérimentales. 
Digitizer/Digitizer.tex:La figure~\ref{fig.nhit_proton_ebeam} montre le nombre total de hits moyen pour les données de la ligne H6, pour une simulation de pions et de protons avec les listes physiques FTFP\_BERT\_HP et QGSP\_BERT\_HP. Au dessus de 40 $GeV$, le nombre total de hits est légèrement plus élevé pour les gerbes hadroniques initiées par des protons que par des pions. Plusieurs facteurs permettent d'expliquer ces différences. La fraction électromagnétique des gerbes hadroniques initiées par des protons est généralement plus faible que pour celles initiées par des pions (cf. section~\ref{sec.fem} du chapitre~\ref{chap.shower}). Ainsi la saturation de la réponse du SDHCAL est plus faible avec les cascades initiées par des protons. De plus, la longueur d'interaction est plus faible pour les protons que pour les pions ($\lambda_I^{\pi}/\lambda_I^p=1.25$ dans l'acier). La fraction d'énergie qui s'échappe du détecteur est donc plus faible pour les protons que pour les pions. Cependant, le nombre de hits pour une simulation de protons reste toujours significativement plus faible que dans les données à haute énergie. La déviation relative est supérieure à 10$\%$ au dessus de 60 $GeV$. 
ILC/ILC.tex:  \caption{Précision attendue pour les couplages de différentes particules au boson de Higgs. Pour les modes de désintégration du Higgs en signal invisible, une limite supérieur est donnée avec un taux de confiance à 95$\%$. Les quatre colonnes présentent les précisions attendues pour le LHC avec une luminosité de 300 $fb^{-1}$; l'ILC à 250 $GeV$ avec 250 $fb^{-1}$; l'ILC à 500 $GeV$ avec 500 $fb^{-1}$; et l'ILC à 1 $TeV$ avec 1000~$fb^{-1}$.}
ILC/ILC.tex:La figure~\ref{fig:ecalOpt}(a) montre la résolution en énergie des jets en fonction du nombre de couches actives avec des galettes de silicium. La taille du calorimètre et son budget matière restent inchangés. La dégradation de la résolution en passant de 30 à 20 couches est environ de 10$\%$.  En réduisant encore le nombre de couches, la détérioration est plus significative, particulièrement à plus basse énergie. La figure~\ref{fig:ecalOpt}(b) montre la résolution en énergie d'événements di-jets en fonction de la proportion du nombre de couches avec des bandes de scintillateur. A basse énergie, la résolution n'est pas influencée par le nombre de couches avec des scintillateurs. A plus haute énergie, une détérioration significative est observée lorsque la proportion du nombre de couches de scintillateur est supérieure à 50$\%$.
SDHCAL/SDHCAL.tex:Les points verts, bleus et rouges correspondent aux hits enregistrés avec les seuils 1, 2 et 3 respectivement. On constate que les hits associés aux deux seuils supérieurs sont majoritairement situés au centre de la cascade où la densité de particules secondaires est théoriquement la plus importante. Nous verrons par la suite comment les informations relatives aux trois seuils nous aident à améliorer les performances du détecteur. De plus, sur la figure~\ref{fig:shower80} on distingue des branches où aucune nouvelle particule secondaire n'est créée. Cette reconstruction fera l'objet d'une étude dédiée dans le chapite~\ref{chap.topo}. La reconstruction de ces branches est utilisée lors de l'identification des particules dans le prototype (voir section~\ref{sec.pi_selection}). Elle est aussi utilisée pour améliorer la mesure de l'énergie des gerbes hadroniques.
SDHCAL/SDHCAL.tex:Cependant, les courbes permettant d'obtenir les facteurs de conversion (voir figure~\ref{dac-vs-inj}), ne sont pas linéaires sur toute la gamme. Ceci est particulièrement visible pour les seuils supérieurs, comme le montre la figure~\ref{dac-vs-inj_12}.
SDHCAL/SDHCAL.tex:La figure~\ref{fig:map_and_rate}(a) montre un exemple de carte de gains pour une chambre du prototype. Les zones en bleu correspondent aux zones les plus bruyantes et sont presque masquées après la correction. Les zones blanches sont, soit des zones non bruyantes, soit des zones déjà masquées. Le gain maximal est appliqué aux canaux non bruyants. La figure~\ref{fig:map_and_rate}(b) montre la distribution du taux de bruit pour chaque canal avant et après la correction de gains. Après les correction de gains, le nombre de canal ayant un taux de bruits supérieur à 100 $Hz$ diminue sensiblement. Ceci a pour effet d'améliorer nos conditions de prise de données. En effet, le temps d'acquisition qui correspond au temps entre le début d'un cycle d'acquisition et le signal RAMfull augmente sensiblement après les corrections de gains (43 $ms$ après corrections contre 22 $ms$ avant). Cela nous permet d'obtenir plus rapidement la statistique d’événements nécessaire pour l'analyse.
SDHCAL/SDHCAL.tex:Lorsque dans un créneau d'horloge $t_0$ (1 créneau=200 $ns$), le nombre de hits est suffisant (>7 sur la figure~\ref{fig:time_spectrum}), un candidat d'événement physique est créé. Ce candidat est conservé seulement s'il correspond à un maximum local ($\Delta_t=600~ns$) de la distribution de la figure~\ref{fig:time_spectrum}. Les hits dans les créneaux adjacents ($t=t_0\pm200~ns$) sont ajoutés aux candidats. Cependant, il a été observé que certaines DIFs pouvaient se désynchroniser des autres d'un coup d'horloge. Pour un faible nombre d'événements, un certain nombre de hits n'apparaissaient pas dans l'événement et les gerbes hadroniques reconstruites semblaient "trouées". Ainsi, la fenêtre de temps pour construire les événements physiques a dû être augmentée ($t=t_0\pm 2\times200~ns$). Un événement physique est finalement reconstruit si le nombre de plans de GRPC avec au moins un hit est supérieur à un paramètre donné ($N_{plans}>=5$ par défaut). Le format des événements physiques est légèrement différent des événement RAMfull. Il contient le temps du RAMfull, le temps relatif au début de leur cycle d'acquisition, les coordonnées des positions de touts les hits de l'événement physique et leur seuil associé. Les hits dans les fenêtres de temps, rejetées par cette procédure sont utilisés pour estimer le bruit du détecteur. 
SDHCAL/SDHCAL.tex:où les $d_i$ correspondent aux distances (en $mm$) entre le barycentre des amas de hits et la droite définie par les coefficients obtenus lors des régressions linéaires. Les événements dont le $\chi^2$ est supérieur à 100 sont rejetés. Ces sélections ont été testées avec des échantillons de simulation de muons dans le SDHCAL. L'efficacité de sélection obtenue avec la simulation est proche de 96$\%$.
SDHCAL/SDHCAL.tex:\item $\frac{N_{IP}}{N_{plans}}>0.1$, où $N_{IP}$ correspond au nombre de plans pour lesquels l'écart type de la position des hits est supérieur à 5 $cm$. Cette coupure permet de rejeter les muons radiatifs. La figure~\ref{fig:muon-rad} montre un exemple de muon radiatif de 50 $GeV$ dans le prototype du SDHCAL.
SDHCAL/SDHCAL.tex:La figure~\ref{fig:energy_sd} présente la valeur moyenne de l'énergie reconstruite des gerbes hadroniques en fonction de l'énergie du faisceau en utilisant le mode multi-seuils pour des échantillons de données enregistrés sur la ligne H2 et H6 du CERN. La déviation relative ($\frac{E_{reco}-E_{beam}}{E_{beam}}$) est en dessous de 5 $\%$ sur toute la gamme d'énergie pour la ligne H2. Seule deux points ont une déviation relative supérieur à 5$\%$ pour les échantillons de données de la ligne H6. L'incertitude de mesure à 5 $GeV$ est très élevée. A 60 $GeV$, la non linéarité de l'énergie reconstruite des hadrons de la ligne H6 peut s'expliquer par la contamination par les protons pour lesquels la réponse du prototype SDHCAL (nombre de hits) est plus élevée (\textcolor{red}{il faut nhit vs energy pour novembre}).
Shower/Shower.tex:Dans les cœur des gerbes hadroniques et électromagnétiques, de nombreux points sont alignés alors que la motivation de la méthode est d'identifier les traces générées par une seule particule. Il faut une procédure pour filtrer la partie dense des cascades avant d'appliquer la méthode. De plus, la Transformée de Hough est appliquée aux amas reconstruits plutôt qu'aux cellules touchées. Ceci permet d'absorber le phénomène de multiplicité et de gagner du temps de calcul. Les amas de hits sont construits avec la méthode standard (cf. chapitre~\ref{chap.sdhcal}). Les coordonnées des barycentres des amas sont ensuite utilisées comme variables de position dans la suite. Un amas appartient à la partie dense de la cascade si son nombre de hits est strictement supérieur à 4; si le nombre d'amas situés à moins de 5 cm de celui-ci est supérieur à 2; ou si un amas avec plus de 4 cellules touchées est trouvé dans un rayon de moins de 5 cm. Les amas de la partie dense ne sont pas utilisés dans l'algorithme de reconstruction des traces. La Transformée de Hough est ensuite appliquée aux amas restants:
Shower/Shower.tex:\item Si le maximum $C_{y,max}$ est supérieur à 6, une trace est créée. Certains amas de cellules touchées peuvent être alignés avec la trace sans pour autant être générés par la même particule. Ainsi, pour chaque amas de la trace, si aucun autre amas de la trace n'est trouvé à moins de trois plan, cet amas est rejeté de la trace. 
ShowerTh/ShowerTh.tex:Cette formule nécessite quelques modifications pour décrire la perte d'énergie par unité de longueur pour les électrons et les positons. Les électrons et les positons subissent des diffusions dans le milieu. Les électrons déposent de l'énergie grâce à la diffusion M{\o}ller ($e^-e^-\rightarrow e^-e^-$) et les positons à travers la diffusion BhaBha ($e^+e^-\rightarrow e^+e^-$). Les positons de basse énergie (E<100 $MeV$) peuvent aussi s'annihiler avec les électrons des atomes du milieu. Cette annihilation entraîne l'émission de deux photons d'énergie au moins supérieur à 511 $keV$.
ShowerTh/ShowerTh.tex:L'effet photoélectrique a été mis en évidence par Hertz en 1887. Il correspond à l'émission d'électrons par un matériau soumis à un rayonnement. Pour éjecter un électron de sa couche, il faut que l'énergie du photon soit supérieure à l'énergie de liaison de l'électron. Ce phénomène est le processus avec la plus grande section efficace pour des photons de basse énergie. La section efficace de l'effet photoélectrique varie comme $1/E$ mais présente des sauts lorsque l'énergie du photon incident est égal à l'énergie de liaison d'une couche électronique.
ShowerTh/ShowerTh.tex:À plus haute énergie, le processus ayant la plus grande section efficace est le processus de création de paire. Lorsque l'énergie du photon est au moins supérieure à deux fois la masse de l'électron, une paire électron-positon peut être créée. La plupart des conversions $\gamma\rightarrow e^+e^-$ sont dues aux champs électromagnétiques des noyaux. Pour des milieux de faible $Z$, le champ électromagnétique, créé par les couches électroniques des atomes, peut engendrer des créations de paires. Si l'énergie du photon incident est suffisante, les électrons et les positons rayonneront d'autres photons grâce au processus de Bremsstrahlung, ou perdront leur énergie avec les processus décrits précédemment.
ShowerTh/ShowerTh.tex:Prenons l'exemple d'une cascade initiée par un électron pour décrire le phénomène de gerbe électromagnétique. Lorsqu'un électron de haute énergie traverse un matériau, le rayonnement de freinage est de loin son mode privilégié de perte d'énergie (cf. figure~\ref{fig:electron_in_lead}). Les photons émis vont se convertir en paires électron-positon qui vont à leur tour perdre de l'énergie sous forme de rayonnement. Ces interactions créent un phénomène de cascade. Les photons peuvent se convertir en paire, tant que leur énergie est supérieur à 1022 $keV$. La cascade se terminera avec les processus de basse énergie comme la diffusion Compton, l'effet photoélectrique, l'annihilation de positon etc.
